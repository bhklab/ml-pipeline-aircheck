
run_name: "run_test"
experiment_name: "WDR91_Experiment" # Experiment Name

#==========================================================================
protein_name: "WDR91" # Protein Name
Train: 'Y' # Running trian phase (N:for no, Y: for yes)
Test: 'Y' # Running test phase (N:for no, Y: for yes)
Screen: 'Y'  # Running test phase (N:for no, Y: for yes)
#==========================================================================


# Data:

train_data: [Data/TrainFiles/small_train.parquet]
test_data: [Data/TestFiles/small_test.parquet]
            
# desired_columns:  [ECFP4, ECFP6, FCFP4, FCFP6, TOPTOR, MACCS, RDK, AVALON, ATOMPAIR]                
desired_columns: [ECFP4, ECFP6] # Correct format: [ECFP4], and [ECFP4, ECFP6, ...] if multuple columns
label_column_train: [LABEL]
label_column_test: [LABEL]
nrows_train: 'None' # integer or 'None' 
nrows_test: 'None'

# Note: selecting feature fusion makes the code so slow. Avoid it for big datasets!!
feature_fusion_method: 'Pairwise' # options: None, All, Pairwise

# create_balanced_datasets
balance_flag: False # Creating blanced train sets (True/False)
balance_ratios: [1] # balance_ratios: [1, 2, 4, 8]
#==========================================================================


# Screening:
#==========================================================================
screen_data: [Data/ScreenFiles/ScreenData1.csv, Data/ScreenFiles/ScreenData2.csv]
smiles_column: "SMILES"
chemistry_filters: 'y' #  (N:for no, Y: for yes)
#==========================================================================



# Model
#==========================================================================
# Supported models:
# rf: Random Forest
# lr: Logistic Regression
# svc: Support Vector Classifier
# nb: Gaussian Naive Bayes
# dt: Decision Tree
# knn: K-Nearest Neighbors
# gb: Gradient Boosting
# ada: AdaBoost
# bag: Bagging Classifier
# mlp: Multi-layer Perceptron
# lgbm:
# catboost:
# tf_ff: tensorflow simple feed forward neural network
# desired_models: [rf, lr, sgd, svc, nb, dt, knn, gb, ada, bag, mlp, lgbm, catboost, tf_ff, tf_cnn1D]
desired_models: [lr]

# Models' Hyperparameters tuning
hyperparameters_tuning: 'N' #  (N:for no, Y: for yes)

# Specifying hyperparameters
hyperparameters: {tf_ff: {input_shape: 2048, hidden_units: [128, 64], learning_rate: 0.0005}}
# {rf:{n_estimators: 150, max_depth: 10}} # hyperparameters: {}  # use default
# UsedHyperParameters: {rf: {n_estimators: 150, max_depth: 10}, tf_ff: {input_shape: 2048, hidden_units: [128, 64], learning_rate: 0.0005}, tf_cnn1D: {input_shape: 2048, conv_layers: [[64, 3], [32, 3]], ff_layers: [64, 32], learning_rate: 0.001}}

# Cross validation
Nfold: 2 # Number of folds for the Crossfold validatrion method
#==========================================================================


# Conformal Prediction
#==========================================================================
conformal_prediction: 'N' # Running conformal prediction (N:for no, Y: for yes)
confromal_test_size: 0.3
confromal_confidence_level: 0.95
#==========================================================================



# Model selection
#==========================================================================
trainfile_for_modelselection: [] # If empty, the top model by evaluation columns and result on the evaluation set is selected. Example: trainfile_for_modelselection: WDR91_SGC.parquet
evaluationfile_for_modelselection: [] # If empty, the top model by evaluation columns is selected. Exmple: evaluationfile_for_modelselection: evaluation.parquet
evaluation_column: [Test_HitsAt200, Test_HitsAt500, Test_PrecisionAt200, Test_PrecisionAt500, Test_TotalHits, Test_F1 Score, Test_Precision, Test_Recall, Test_Accuracy, Test_PlatePPV]
crossvalidation_column: [CV_HitsAt200, CV_HitsAt500, CV_PrecisionAt200, CV_PrecisionAt500, CV_TotalHits, CV_F1Score, CV_Precision, CV_Recall, CV_Accuracy, CV_PlatePPV]
#==========================================================================



# Model Fusion
#==========================================================================
Fusion: 'y' # Running model fusion (N:for no, Y: for yes)
num_top_models: 2
#==========================================================================





