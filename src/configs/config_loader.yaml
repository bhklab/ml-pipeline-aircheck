ml-pipeline:
  version: 1.0.0
  description: "AIRCHECK ML Pipeline Configuration"
  run_name: "run_test"
  experiment_name: "WDR91_Experiment_test_one" # Experiment Name
  
  protein_name: "WDR91" # Target Name
  is_train: True # Running train phase (False:for no, True: for yes)
  is_test: True # Running test phase (False:for no, True: for yes)
  is_screen: True  # Running screen phase (False:for no, True: for yes)
  

  # Data:

  train_data:
    - ./data/TrainFiles/company1.parquet

  test_data:
    - ./data/TestFiles/sampled_data_test_1.parquet

  # desired_columns:  [ECFP4, ECFP6, FCFP4, FCFP6, TOPTOR, MACCS, RDK, AVALON, ATOMPAIR]
  desired_columns:
    - ECFP4 # Correct format: [ECFP4], and [ECFP4, ECFP6, ...] if multuple columns
  label_column_train: LABEL
  label_column_test: LABEL
  nrows_train: None # integer or None
  nrows_test: None

  # Note: selecting feature fusion makes the code so slow. Avoid it for big datasets!!
  feature_fusion_method: None # options: None, All, Pairwise

  # create_balanced_datasets
  balance_flag: False # Creating blanced train sets (True/False)
  balance_ratios:  # balance_ratios: [1, 2, 4, 8]
    - 1 # Ratio of positive to negative samples in the balanced dataset
    


  # Screening:
  screen_data: 
    - Data/ScreenFiles/ScreenData1.csv
    - Data/ScreenFiles/ScreenData2.csv
  smiles_column: SMILES # Column name for SMILES in the screening data
  is_chemistry_filters: True #  (N:for no, Y: for yes)


  # To Upload mlflow files to GCS
  bucket_name: "test-aircheck"
  prefix_name: "mlflow-logging"


  # Model
  # Supported models:
  # rf: Random Forest
  # lr: Logistic Regression
  # svc: Support Vector Classifier
  # nb: Gaussian Naive Bayes
  # dt: Decision Tree
  # knn: K-Nearest Neighbors
  # gb: Gradient Boosting
  # ada: AdaBoost
  # bag: Bagging Classifier
  # mlp: Multi-layer Perceptron
  # lgbm:
  # catboost:
  # desired_models: [rf, lr, sgd, svc, nb, dt, knn, gb, ada, bag, mlp, lgbm, catboost]
  desired_models: 
    - lgbm


  # Models' Hyperparameters tuning
  hyperparameters_tuning: False #  (N:for no, Y: for yes)
  tf_models:
    - tf_ff
    - tf_cnn1D
  # Specifying hyperparameters
  hyperparameters:
    tf_ff:
      input_shape: 2048
      hidden_units:
        - 128
        - 64
      learning_rate: 0.0005

  # Cross validation
  Nfold: 2 # Number of folds for the Crossfold validatrion method
  

  # Conformal Prediction
  
  conformal_prediction: False # Running conformal prediction (N:for no, Y: for yes)
  conformal_test_size: 0.3
  conformal_confidence_level: 0.95
  


  # Model selection
  trainfile_for_modelselection: [] # If empty, the top model by evaluation columns and result on the evaluation set is selected. Example: trainfile_for_modelselection: WDR91_SGC.parquet
  evaluationfile_for_modelselection: [] # If empty, the top model by evaluation columns is selected. Exmple: evaluationfile_for_modelselection: evaluation.parquet
  evaluation_column: 
    - Test_HitsAt200
    - Test_HitsAt500
    - Test_PrecisionAt200
    - Test_PrecisionAt500
    - Test_TotalHits
    - Test_F1 Score
    - Test_Precision
    - Test_Recall
    - Test_Accuracy
    - Test_PlatePPV
  crossvalidation_column: 
    - CV_HitsAt200
    - CV_HitsAt500
    - CV_PrecisionAt200
    - CV_PrecisionAt500
    - CV_TotalHits
    - CV_F1Score
    - CV_Precision
    - CV_Recall
    - CV_Accuracy
    - CV_PlatePPV
  
  # Model Fusion

  Fusion: True # Running model fusion (N:for no, Y: for yes)
  num_top_models: 2

  cleanup_after_run: True


